{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-PeiN30VJQ63"
   },
   "source": [
    "# Cross validation\n",
    "\n",
    "Outer k-fold cross validation as an alternative assessment method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z09cFxkBLNbR"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "import constants\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "adg_data = pd.read_csv('variables/processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adg_data.iloc[:,:constants.FEATURES_NUM]\n",
    "y = adg_data.iloc[:,constants.FEATURES_NUM:]\n",
    "\n",
    "# Define the outer cross-validation\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "models=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"]\n",
    "\n",
    "# Define the model and pipeline components\n",
    "pipelines = [Pipeline([\n",
    "    ('scaler', StandardScaler()),            \n",
    "    ('feature_select', SelectFromModel(Lasso(random_state=12))), \n",
    "    ('model', LinearRegression())                       \n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('scaler', StandardScaler()),            \n",
    "    ('feature_select', SelectFromModel(Lasso(random_state=12))), \n",
    "    ('model', Lasso(random_state=12))                       \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', Ridge(random_state=12))                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', KNeighborsRegressor())                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', RandomForestRegressor(random_state=12))                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('model', RandomForestRegressor(random_state=12))                     \n",
    "    ]),\n",
    "    ]\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grids = [\n",
    "    {},\n",
    "    {\n",
    "    'model__alpha': [0.01,0.1, 1.0, 10.0]         \n",
    "    },\n",
    "    {\n",
    "    'model__alpha': [0.1, 1.0, 10.0]         # Ridge regularization strength\n",
    "    },\n",
    "    {'model__n_neighbors': [3, 5, 7, 9],\n",
    "    'model__metric': ['jaccard_score', 'hamming_loss','manhattan_distances','cosine_similarity']\n",
    "     },\n",
    "    {\n",
    "        'model__max_depth': [5, 10, 20, 80, 90, 100],\n",
    "        'model__max_features': [1,2, 3],\n",
    "        'model__n_estimators': [50, 80, 100]\n",
    "    },\n",
    "    {\n",
    "        'model__max_depth': [5, 10, 20, 80, 90, 100],\n",
    "        'model__max_features': [1,2, 3],\n",
    "        'model__n_estimators': [50, 80, 100]\n",
    "    }]\n",
    "\n",
    "mae_df = pd.DataFrame(index=y.columns,columns=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"])\n",
    "std_df = pd.DataFrame(index=y.columns,columns=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"])\n",
    "\n",
    "# Store results\n",
    "outer_results = []\n",
    "\n",
    "for i in range(16):\n",
    "    y_i = y.iloc[:,i]\n",
    "    tmp_maes = []\n",
    "    tmp_stds = []\n",
    "    for setup in range(len(models)):\n",
    "        pipeline = pipelines[setup]\n",
    "        model = models[setup]\n",
    "        param_grid = param_grids[setup]\n",
    "        print(f\"Model: {models[setup]}, Target: {y.columns[i]}\")\n",
    "        tmp_maes_folds = []\n",
    "        tmp_stds_folds = []\n",
    "        # Outer CV loop\n",
    "        for train_idx, test_idx in outer_cv.split(X, y_i):\n",
    "            # Split data into training and test sets for this fold\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y_i.iloc[train_idx], y_i.iloc[test_idx]\n",
    "            \n",
    "            # Inner CV: Hyperparameter tuning\n",
    "            inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            grid_search = GridSearchCV(pipeline, param_grid, cv=inner_cv, scoring='neg_mean_absolute_error')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "            # Evaluate on the outer test set\n",
    "            best_model = grid_search.best_estimator_\n",
    "            print(f\"Best Model: {best_model}\")\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            std = np.std(y_test - y_pred)\n",
    "\n",
    "            tmp_maes_folds.append(mae)\n",
    "            tmp_stds_folds.append(std)\n",
    "\n",
    "\n",
    "            # Print results for this outer fold\n",
    "            print(f\"Fold MAE: {mae:.4f}, Best Params: {grid_search.best_params_}\")\n",
    "\n",
    "        tmp_maes.append(np.mean(tmp_maes_folds))\n",
    "        tmp_stds.append(np.mean(tmp_stds_folds))    \n",
    "        print(f\"Mean MAE across folds: {np.mean(tmp_maes_folds):.4f}\")\n",
    "    mae_df.iloc[i] = tmp_maes\n",
    "    std_df.iloc[i] = tmp_stds\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "startcol = 0\n",
    "# Create an empty excel file in the same folder before executing this\n",
    "with pd.ExcelWriter(\"test_results_cv.xlsx\", engine='openpyxl', mode=\"a\") as writer:\n",
    "    # Write each DataFrame to a separate sheet\n",
    "    mae_df.to_excel(writer, sheet_name='MAE',startcol=startcol, index=False)\n",
    "    std_df.to_excel(writer, sheet_name='STD',startcol=startcol,index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "st_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
