{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "-PeiN30VJQ63"
   },
   "source": [
    "# Cross validation\n",
    "\n",
    "Outer k-fold cross validation as an alternative assessment method. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Z09cFxkBLNbR"
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "import pandas as pd\n",
    "import constants\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import constants\n",
    "\n",
    "\n",
    "adg_data = pd.read_csv('variables/processed.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = adg_data.iloc[:,:constants.FEATURES_NUM]\n",
    "y = adg_data.iloc[:,constants.FEATURES_NUM:]\n",
    "\n",
    "# Define the outer cross-validation\n",
    "outer_cv = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "models=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"]\n",
    "\n",
    "# Define the model and pipeline components\n",
    "pipelines = [Pipeline([\n",
    "    ('scaler', StandardScaler()),            \n",
    "    ('model', LinearRegression())                       \n",
    "    ]),\n",
    "    Pipeline([\n",
    "    ('scaler', StandardScaler()),            \n",
    "    ('feature_select', SelectFromModel(Lasso(random_state=12))), \n",
    "    ('model', Lasso(random_state=12))                       \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', Ridge(random_state=12))                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', KNeighborsRegressor())                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('feature_select', SelectFromModel(Lasso(random_state=12))),  \n",
    "        ('model', RandomForestRegressor(random_state=12))                     \n",
    "    ]),\n",
    "    Pipeline([\n",
    "        ('scaler', StandardScaler()),            \n",
    "        ('model', RandomForestRegressor(random_state=12))                     \n",
    "    ]),\n",
    "    ]\n",
    "\n",
    "# Define hyperparameters to tune\n",
    "param_grids = [\n",
    "    {},\n",
    "    {\n",
    "    'model__alpha': [0.01,0.1, 1.0, 10.0]         \n",
    "    },\n",
    "    {\n",
    "    'model__alpha': [0.1, 1.0, 10.0]         # Ridge regularization strength\n",
    "    },\n",
    "    {'model__n_neighbors': [3, 5, 7, 9],\n",
    "    'model__metric': ['jaccard_score', 'hamming_loss','manhattan_distances','cosine_similarity']\n",
    "     },\n",
    "    {\n",
    "        'model__max_depth': [5, 10, 20, 80, 90, 100],\n",
    "        'model__max_features': [1,2, 3],\n",
    "        'model__n_estimators': [50, 80, 100]\n",
    "    },\n",
    "    {\n",
    "        'model__max_depth': [5, 10, 20, 80, 90, 100],\n",
    "        'model__max_features': [1,2, 3],\n",
    "        'model__n_estimators': [50, 80, 100]\n",
    "    }]\n",
    "\n",
    "mae_df = pd.DataFrame(index=y.columns,columns=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"])\n",
    "std_df = pd.DataFrame(index=y.columns,columns=[\"LR\",\"Lasso\",\"Ridge\",\"KNN\",\"RF\",\"RF_all\"])\n",
    "mae_df_naive = pd.DataFrame(index=y.columns,columns=[\"yavg\",\"xavg\",\"x\"])\n",
    "std_df_naive = pd.DataFrame(index=y.columns,columns=[\"yavg\",\"xavg\",\"x\"])\n",
    "\n",
    "# Store results\n",
    "outer_results = []\n",
    "\n",
    "naive_maesyavg = []\n",
    "naive_stdsyavg = []\n",
    "naive_maesx = []\n",
    "naive_stdsx = []\n",
    "naive_maesxavg = []\n",
    "naive_stdsxavg = []\n",
    "\n",
    "for i in range(16):\n",
    "    y_i = y.iloc[:,i]\n",
    "    tmp_maes = []\n",
    "    tmp_stds = []\n",
    "    computed_naive = False\n",
    "    naive_maesyavg_folds = []\n",
    "    naive_stdsyavg_folds = []\n",
    "    naive_maesx_folds = []\n",
    "    naive_stdsx_folds = []\n",
    "    naive_maesxavg_folds = []\n",
    "    naive_stdsxavg_folds = []\n",
    "    for setup in range(len(models)):\n",
    "        pipeline = pipelines[setup]\n",
    "        model = models[setup]\n",
    "        param_grid = param_grids[setup]\n",
    "        print(f\"Model: {models[setup]}, Target: {y.columns[i]}\")\n",
    "        tmp_maes_folds = []\n",
    "        tmp_stds_folds = []\n",
    "        # Outer CV loop\n",
    "        for train_idx, test_idx in outer_cv.split(X, y_i):\n",
    "            # Split data into training and test sets for this fold\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y_i.iloc[train_idx], y_i.iloc[test_idx]\n",
    "            \n",
    "            # Inner CV: Hyperparameter tuning\n",
    "            inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "            grid_search = GridSearchCV(pipeline, param_grid, cv=inner_cv, scoring='neg_mean_absolute_error')\n",
    "            grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "            # Evaluate on the outer test set\n",
    "            best_model = grid_search.best_estimator_\n",
    "            print(f\"Best Model: {best_model}\")\n",
    "            y_pred = best_model.predict(X_test)\n",
    "            mae = mean_absolute_error(y_test, y_pred)\n",
    "            std = np.std(y_test - y_pred)\n",
    "\n",
    "            if not computed_naive:\n",
    "                #Naive predictions\n",
    "                y_avg = np.mean(y_train)\n",
    "                x_avg = np.mean(X_train[constants.FQ_FEATURES[i]])\n",
    "                x_naive = X_test[constants.FQ_FEATURES[i]]\n",
    "\n",
    "                test_mean_vect = np.zeros((y_test.shape[0],1))\n",
    "                test_mean_vect += y_avg\n",
    "                test_mean_vect = test_mean_vect.reshape(-1)\n",
    "                naive_mae = mean_absolute_error(y_test,test_mean_vect)\n",
    "                #print(naive_mae)\n",
    "                naive_maesyavg_folds.append(naive_mae)\n",
    "                naive_stdsyavg_folds.append(np.std(y_test - test_mean_vect))\n",
    "\n",
    "                naive_mae = mean_absolute_error(y_test,x_naive)\n",
    "                #print(naive_mae)\n",
    "                naive_maesx_folds.append(naive_mae)\n",
    "                naive_stdsx_folds.append(np.std(y_test - x_naive))\n",
    "\n",
    "                test_mean_vect = np.zeros((y_test.shape[0],1))\n",
    "                test_mean_vect += x_avg\n",
    "                test_mean_vect = test_mean_vect.reshape(-1)\n",
    "                naive_mae = mean_absolute_error(y_test,test_mean_vect)\n",
    "                #print(naive_mae)\n",
    "                naive_maesxavg_folds.append(naive_mae)\n",
    "                naive_stdsxavg_folds.append(np.std(y_test - test_mean_vect))\n",
    "\n",
    "            tmp_maes_folds.append(mae)\n",
    "            tmp_stds_folds.append(std)\n",
    "\n",
    "\n",
    "            # Print results for this outer fold\n",
    "            print(f\"Fold MAE: {mae:.4f}, Best Params: {grid_search.best_params_}\")\n",
    "        computed_naive = True\n",
    "        tmp_maes.append(np.mean(tmp_maes_folds))\n",
    "        tmp_stds.append(np.mean(tmp_stds_folds))    \n",
    "        print(f\"Mean MAE across folds: {np.mean(tmp_maes_folds):.4f}\")\n",
    "    naive_maesyavg.append(np.mean(naive_maesyavg_folds))\n",
    "    naive_stdsyavg.append(np.mean(naive_stdsyavg_folds))\n",
    "    naive_maesx.append(np.mean(naive_maesx_folds))\n",
    "    naive_stdsx.append(np.mean(naive_stdsx_folds))\n",
    "    naive_maesxavg.append(np.mean(naive_maesxavg_folds))\n",
    "    naive_stdsxavg.append(np.mean(naive_stdsxavg_folds))\n",
    "    mae_df.iloc[i] = tmp_maes\n",
    "    std_df.iloc[i] = tmp_stds\n",
    "    \n",
    "mae_df_naive[\"yavg\"] = naive_maesyavg\n",
    "mae_df_naive[\"x\"] = naive_maesx\n",
    "mae_df_naive[\"xavg\"] = naive_maesxavg\n",
    "\n",
    "std_df_naive[\"yavg\"] = naive_stdsyavg\n",
    "std_df_naive[\"x\"] = naive_stdsx \n",
    "std_df_naive[\"xavg\"] = naive_stdsxavg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  yavg       xavg          x\n",
      "125AftAir    10.506136  25.218657  24.725806\n",
      "250AftAir     9.163248  28.072474  27.196237\n",
      "500AftAir     9.019908  30.677088  30.034946\n",
      "1000AftAir    9.111491  26.587015  25.754032\n",
      "1500AftAir    9.754471  22.317662  20.443548\n",
      "2000AftAir   11.361296  22.595109  20.854839\n",
      "3000AftAir   14.308984  21.829564  18.815860\n",
      "4000AftAir   15.696032  20.145025  16.184140\n",
      "6000AftAir   17.845664  19.312539  14.901882\n",
      "8000AftAir   19.567808  19.571607  12.263441\n",
      "500AftBone    5.329087   7.505084   4.790323\n",
      "1000AftBone   6.608725   8.300598   5.198925\n",
      "1500AftBone   9.805156  10.975923   6.788978\n",
      "2000AftBone  11.454097  12.435377   6.387097\n",
      "3000AftBone  13.413414  14.062734   5.700269\n",
      "4000AftBone  14.024301  14.013324   5.211022\n",
      "                  yavg       xavg          x\n",
      "125AftAir    12.651983  12.651983  13.383100\n",
      "250AftAir    12.011830  12.011830  12.416251\n",
      "500AftAir    11.730643  11.730643  12.694755\n",
      "1000AftAir   11.608666  11.608666  11.032491\n",
      "1500AftAir   12.904896  12.904896  10.943188\n",
      "2000AftAir   14.123643  14.123643  10.546137\n",
      "3000AftAir   16.509157  16.509157  11.654042\n",
      "4000AftAir   18.583730  18.583730  13.661822\n",
      "6000AftAir   20.343790  20.343790  15.396099\n",
      "8000AftAir   22.420607  22.420607  16.363316\n",
      "500AftBone    6.760092   6.760092   6.669612\n",
      "1000AftBone   8.485398   8.485398   6.155386\n",
      "1500AftBone  11.875853  11.875853   8.025835\n",
      "2000AftBone  13.719117  13.719117   8.451363\n",
      "3000AftBone  15.422601  15.422601   7.358233\n",
      "4000AftBone  16.264108  16.264108   7.655677\n"
     ]
    }
   ],
   "source": [
    "print(mae_df_naive)\n",
    "print(std_df_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "startcol = 0\n",
    "# Create an empty excel file in the same folder before executing this\n",
    "with pd.ExcelWriter(\"test_results_cv.xlsx\", engine='openpyxl', mode=\"a\") as writer:\n",
    "    # Write each DataFrame to a separate sheet\n",
    "    mae_df.to_excel(writer, sheet_name='MAE',startcol=startcol, index=False)\n",
    "    std_df.to_excel(writer, sheet_name='STD',startcol=startcol,index=False)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "st_pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
